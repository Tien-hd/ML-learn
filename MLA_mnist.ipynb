{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8680785",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-16T13:31:09.087826Z",
     "iopub.status.busy": "2024-04-16T13:31:09.087396Z",
     "iopub.status.idle": "2024-04-16T13:31:10.129163Z",
     "shell.execute_reply": "2024-04-16T13:31:10.127785Z"
    },
    "papermill": {
     "duration": 1.050483,
     "end_time": "2024-04-16T13:31:10.131880",
     "exception": false,
     "start_time": "2024-04-16T13:31:09.081397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mnist-dataset/train-images.idx3-ubyte\n",
      "/kaggle/input/mnist-dataset/t10k-labels.idx1-ubyte\n",
      "/kaggle/input/mnist-dataset/t10k-images.idx3-ubyte\n",
      "/kaggle/input/mnist-dataset/train-labels.idx1-ubyte\n",
      "/kaggle/input/mnist-dataset/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte\n",
      "/kaggle/input/mnist-dataset/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte\n",
      "/kaggle/input/mnist-dataset/train-labels-idx1-ubyte/train-labels-idx1-ubyte\n",
      "/kaggle/input/mnist-dataset/train-images-idx3-ubyte/train-images-idx3-ubyte\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c8faf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:31:10.141905Z",
     "iopub.status.busy": "2024-04-16T13:31:10.141325Z",
     "iopub.status.idle": "2024-04-16T13:31:10.157592Z",
     "shell.execute_reply": "2024-04-16T13:31:10.156299Z"
    },
    "papermill": {
     "duration": 0.024875,
     "end_time": "2024-04-16T13:31:10.160533",
     "exception": false,
     "start_time": "2024-04-16T13:31:10.135658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        images_ar = np.array(images)\n",
    "        labels_ar = np.array(labels)\n",
    "        return images_ar, labels_ar\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb7aae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:31:10.169880Z",
     "iopub.status.busy": "2024-04-16T13:31:10.169469Z",
     "iopub.status.idle": "2024-04-16T13:31:15.212031Z",
     "shell.execute_reply": "2024-04-16T13:31:15.210757Z"
    },
    "papermill": {
     "duration": 5.050472,
     "end_time": "2024-04-16T13:31:15.214684",
     "exception": false,
     "start_time": "2024-04-16T13:31:10.164212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000) (60000,)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Verify Reading Dataset via MnistDataloader class\n",
    "#\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "# Set file paths based on added MNIST Datasets\n",
    "#\n",
    "training_images_filepath = join('/kaggle/input/mnist-dataset/train-images.idx3-ubyte')\n",
    "training_labels_filepath = join('/kaggle/input/mnist-dataset/train-labels.idx1-ubyte')\n",
    "test_images_filepath = join('/kaggle/input/mnist-dataset/t10k-images.idx3-ubyte')\n",
    "test_labels_filepath = join('/kaggle/input/mnist-dataset/t10k-labels.idx1-ubyte')\n",
    "\n",
    "\n",
    "#\n",
    "# Load MINST dataset\n",
    "#\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "def extract_data(X):\n",
    "    X0 = np.asarray(X)/256\n",
    "    X0 = X0.reshape(X0.shape[0],-1).T\n",
    "    return X0\n",
    "X_train = extract_data(X_train)\n",
    "X_test = extract_data(X_test)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa9f098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:31:15.223497Z",
     "iopub.status.busy": "2024-04-16T13:31:15.223091Z",
     "iopub.status.idle": "2024-04-16T13:42:39.782720Z",
     "shell.execute_reply": "2024-04-16T13:42:39.780956Z"
    },
    "papermill": {
     "duration": 684.569315,
     "end_time": "2024-04-16T13:42:39.787674",
     "exception": false,
     "start_time": "2024-04-16T13:31:15.218359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 60000)\n",
      "(10, 60000)\n",
      "77.46089051183256\n",
      "iter 0, loss: 2.302269\n",
      "82.53275485043918\n",
      "iter 10, loss: 1.925252\n",
      "155.07781388166202\n",
      "iter 20, loss: 0.830688\n",
      "173.64855168184724\n",
      "iter 30, loss: 0.677673\n",
      "196.68992320024668\n",
      "iter 40, loss: 0.496658\n",
      "207.08043760484276\n",
      "iter 50, loss: 0.545617\n",
      "211.75019673481236\n",
      "iter 60, loss: 0.395026\n",
      "214.60735722440273\n",
      "iter 70, loss: 0.393553\n",
      "217.40233178137805\n",
      "iter 80, loss: 0.342942\n",
      "219.16951156095146\n",
      "iter 90, loss: 0.323145\n",
      "220.4368580058433\n",
      "iter 100, loss: 0.309664\n",
      "221.40710463385219\n",
      "iter 110, loss: 0.299578\n",
      "222.19149854125757\n",
      "iter 120, loss: 0.291542\n",
      "222.95784424642304\n",
      "iter 130, loss: 0.281855\n",
      "223.72590361436872\n",
      "iter 140, loss: 0.271060\n",
      "224.39258558176618\n",
      "iter 150, loss: 0.262179\n",
      "224.97291545308912\n",
      "iter 160, loss: 0.254793\n",
      "225.49132090349838\n",
      "iter 170, loss: 0.248191\n",
      "225.96895229198194\n",
      "iter 180, loss: 0.242108\n",
      "226.40720933746286\n",
      "iter 190, loss: 0.236414\n",
      "226.81015278348517\n",
      "iter 200, loss: 0.231030\n",
      "227.18789331072077\n",
      "iter 210, loss: 0.225945\n",
      "227.5467154643051\n",
      "iter 220, loss: 0.221130\n",
      "227.8909690026594\n",
      "iter 230, loss: 0.216568\n",
      "228.21803927538144\n",
      "iter 240, loss: 0.212232\n",
      "228.5268059016293\n",
      "iter 250, loss: 0.208091\n",
      "228.82150514578024\n",
      "iter 260, loss: 0.204137\n",
      "229.10294315227856\n",
      "iter 270, loss: 0.200362\n",
      "229.3731521360229\n",
      "iter 280, loss: 0.196753\n",
      "229.6305390946428\n",
      "iter 290, loss: 0.193293\n",
      "229.87159347862823\n",
      "iter 300, loss: 0.189953\n",
      "230.10376067818612\n",
      "iter 310, loss: 0.186730\n",
      "230.32813111843495\n",
      "iter 320, loss: 0.183623\n",
      "230.544133481224\n",
      "iter 330, loss: 0.180618\n",
      "230.75116383553865\n",
      "iter 340, loss: 0.177711\n",
      "230.94876471009582\n",
      "iter 350, loss: 0.174895\n",
      "231.13996167525534\n",
      "iter 360, loss: 0.172165\n",
      "231.32484614427142\n",
      "iter 370, loss: 0.169510\n",
      "231.50156022132862\n",
      "iter 380, loss: 0.166930\n",
      "231.67503922996312\n",
      "iter 390, loss: 0.164422\n",
      "231.84642058041783\n",
      "iter 400, loss: 0.161985\n",
      "232.0115436755379\n",
      "iter 410, loss: 0.159619\n",
      "232.17404309088488\n",
      "iter 420, loss: 0.157317\n",
      "232.3330103200098\n",
      "iter 430, loss: 0.155081\n",
      "232.48577948396812\n",
      "iter 440, loss: 0.152906\n",
      "232.63479659752184\n",
      "iter 450, loss: 0.150783\n",
      "232.78081619038772\n",
      "iter 460, loss: 0.148713\n",
      "232.92120816564764\n",
      "iter 470, loss: 0.146695\n",
      "233.0587535532187\n",
      "iter 480, loss: 0.144722\n",
      "233.19048197931778\n",
      "iter 490, loss: 0.142792\n",
      "233.31960090799484\n",
      "iter 500, loss: 0.140906\n",
      "233.44377414935855\n",
      "iter 510, loss: 0.139066\n",
      "233.5673482452314\n",
      "iter 520, loss: 0.137270\n",
      "233.68646820102967\n",
      "iter 530, loss: 0.135514\n",
      "233.80536972189017\n",
      "iter 540, loss: 0.133796\n",
      "233.91776158664803\n",
      "iter 550, loss: 0.132111\n",
      "234.0293046986122\n",
      "iter 560, loss: 0.130459\n",
      "234.13711179466188\n",
      "iter 570, loss: 0.128839\n",
      "234.24369761774713\n",
      "iter 580, loss: 0.127251\n",
      "234.34837250505737\n",
      "iter 590, loss: 0.125695\n",
      "234.45238237821437\n",
      "iter 600, loss: 0.124172\n",
      "234.55396841449112\n",
      "iter 610, loss: 0.122682\n",
      "234.6537801098616\n",
      "iter 620, loss: 0.121219\n",
      "234.75145260629148\n",
      "iter 630, loss: 0.119783\n",
      "234.84872848281094\n",
      "iter 640, loss: 0.118379\n",
      "234.94280970650487\n",
      "iter 650, loss: 0.117008\n",
      "235.03517806555865\n",
      "iter 660, loss: 0.115664\n",
      "235.12548693405122\n",
      "iter 670, loss: 0.114345\n",
      "235.21492476892132\n",
      "iter 680, loss: 0.113051\n",
      "235.30312231733745\n",
      "iter 690, loss: 0.111785\n",
      "235.390805641161\n",
      "iter 700, loss: 0.110545\n",
      "235.47466817686535\n",
      "iter 710, loss: 0.109329\n",
      "235.55610671648856\n",
      "iter 720, loss: 0.108137\n",
      "235.63632611957698\n",
      "iter 730, loss: 0.106970\n",
      "235.71552401215357\n",
      "iter 740, loss: 0.105826\n",
      "235.79365248005882\n",
      "iter 750, loss: 0.104703\n",
      "235.8706481804534\n",
      "iter 760, loss: 0.103603\n",
      "235.9469514809883\n",
      "iter 770, loss: 0.102523\n",
      "236.0211329543636\n",
      "iter 780, loss: 0.101463\n",
      "236.0935453043191\n",
      "iter 790, loss: 0.100421\n",
      "236.16394289622008\n",
      "iter 800, loss: 0.099398\n",
      "236.23408395236638\n",
      "iter 810, loss: 0.098394\n",
      "236.30308407665524\n",
      "iter 820, loss: 0.097409\n",
      "236.37005697419866\n",
      "iter 830, loss: 0.096441\n",
      "236.4357159991267\n",
      "iter 840, loss: 0.095488\n",
      "236.50077668030875\n",
      "iter 850, loss: 0.094550\n",
      "236.56497423347554\n",
      "iter 860, loss: 0.093629\n",
      "236.62880848411095\n",
      "iter 870, loss: 0.092724\n",
      "236.69083622462105\n",
      "iter 880, loss: 0.091836\n",
      "236.7515517595293\n",
      "iter 890, loss: 0.090962\n",
      "236.81166737800731\n",
      "iter 900, loss: 0.090103\n",
      "236.8713764589171\n",
      "iter 910, loss: 0.089258\n",
      "236.93036152738944\n",
      "iter 920, loss: 0.088428\n",
      "236.98827512795336\n",
      "iter 930, loss: 0.087612\n",
      "237.04481679218495\n",
      "iter 940, loss: 0.086808\n",
      "237.10082143512437\n",
      "iter 950, loss: 0.086020\n",
      "237.1564573524338\n",
      "iter 960, loss: 0.085246\n",
      "237.2110829520966\n",
      "iter 970, loss: 0.084486\n",
      "237.26487252022358\n",
      "iter 980, loss: 0.083739\n",
      "237.31767551515435\n",
      "iter 990, loss: 0.083001\n"
     ]
    }
   ],
   "source": [
    "# softmax\n",
    "def softmax_stable(Z):\n",
    "    e_V = np.exp(Z-np.max(Z,axis=0,keepdims=True))\n",
    "    Z = e_V/e_V.sum(axis=0)\n",
    "    # print(Z)\n",
    "    return Z\n",
    "\n",
    "#onehot coding\n",
    "from scipy import sparse\n",
    "def convert_label(y,C):\n",
    "    Y = sparse.coo_matrix((np.ones_like(y),\n",
    "        (y, np.arange(len(y)))), shape = (C, len(y))).toarray()\n",
    "    return Y\n",
    "\n",
    "# cost or loss function\n",
    "def cost(Y, Yhat):\n",
    "    return -np.sum(Y*np.log(Yhat))/Y.shape[1]\n",
    "\n",
    "\n",
    "d0 = X_train.shape[0]\n",
    "d1 = 100 #hiden layer\n",
    "d2 = 10 #number of class\n",
    "\n",
    "#initial parameters randomly\n",
    "w1 = 0.01*np.random.randn(d0,d1)\n",
    "b1 = np.zeros((d1,1))\n",
    "w2 = 0.01*np.random.randn(d1,d2)\n",
    "b2 = np.zeros((d2,1))\n",
    "\n",
    "N = X_train.shape[1] # number of trainning data points\n",
    "Y = convert_label(Y_train,d2)\n",
    "print(Y.shape)\n",
    "eta = 0.6 #learning rate\n",
    "\n",
    "print(Y.shape)\n",
    "#multi layer perceptron\n",
    "def multi_LP(X,Y,eta,w1,w2,b1,b2):\n",
    "    count = 0\n",
    "    while count < 1000:\n",
    "        # mixdata = np.random.permutation(N)\n",
    "        # for i in mixdata:\n",
    "        # print(count)\n",
    "        # xi = X[:,i].reshape(d0,1)\n",
    "        # yi = Y[:,i].reshape(d2,1)\n",
    "        #feedforward\n",
    "        Z1 = np.dot(w1.T,X) + b1\n",
    "        A1 = np.maximum(Z1,0)\n",
    "        Z2 = np.dot(w2.T,A1) + b2\n",
    "        Yhat = softmax_stable(Z2)\n",
    "            \n",
    "        # print loss after each 1000 iterations\n",
    "        if count %10 == 0:\n",
    "            # compute the loss: average cross-entropy loss\n",
    "            loss = cost(Y, Yhat)\n",
    "            print(np.linalg.norm(Yhat))\n",
    "            print(\"iter %d, loss: %f\" %(count, loss))\n",
    "            \n",
    "        #backpropagation\n",
    "        E2 = (Yhat - Y)/N  #we chose that it define the scale of loss function follow Z2\n",
    "        dw2 = np.dot(A1,E2.T)\n",
    "        db2 = np.sum(E2, axis = 1, keepdims = True)\n",
    "        E1 = np.dot(w2,E2)\n",
    "        E1[Z1 <= 0] = 0  #ReLU\n",
    "        dw1 = np.dot(X,E1.T)\n",
    "        db1 = np.sum(E1, axis = 1, keepdims = True)\n",
    "            \n",
    "        #SGD\n",
    "        w1 += -eta*dw1\n",
    "        b1 += -eta*db1\n",
    "        w2 += -eta*dw2\n",
    "        b2 += -eta*db2\n",
    "            \n",
    "        count += 1\n",
    "            \n",
    "    return w1,w2,b1,b2\n",
    "\n",
    "(w1,w2,b1,b2) = multi_LP(X_train,Y,eta,w1,w2,b1,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcbe8ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:42:39.847302Z",
     "iopub.status.busy": "2024-04-16T13:42:39.846514Z",
     "iopub.status.idle": "2024-04-16T13:42:41.116212Z",
     "shell.execute_reply": "2024-04-16T13:42:41.114753Z"
    },
    "papermill": {
     "duration": 1.302701,
     "end_time": "2024-04-16T13:42:41.119236",
     "exception": false,
     "start_time": "2024-04-16T13:42:39.816535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.12 %\n"
     ]
    }
   ],
   "source": [
    "z1 = np.dot(w1.T,X_test) + b1\n",
    "A1 = np.maximum(z1,0)\n",
    "z2 = np.dot(w2.T,A1) + b2\n",
    "from sklearn.metrics import accuracy_score\n",
    "def pred(Z):\n",
    "    Y_pred  =  softmax_stable(Z)\n",
    "    return np.argmax(Y_pred,axis=0)\n",
    "\n",
    "y_pred = pred(z2)\n",
    "print( \"Accuracy: %.2f %%\" %(100*accuracy_score(Y_test, y_pred.tolist())))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 102285,
     "sourceId": 242592,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 696.133641,
   "end_time": "2024-04-16T13:42:41.855550",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-16T13:31:05.721909",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
